{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e20db5fa-7c88-4f64-9d8f-0458c7a32bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2022.11.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.2.140)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0e6285-9428-4277-8b97-bdc140d05b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5499ba-1211-42c8-be07-85af747644cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e154799-4f43-4a63-826f-0ac14d0c65a2",
   "metadata": {},
   "source": [
    "#### Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "217e6c6d-d274-4847-aaef-f83817cfd9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "157c821d-3839-4fc2-822d-493fc1db4ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36941d5f-6d23-46d1-9a0a-189231d68cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = torch.tensor(6.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eb26c86-1f03-41ef-ae91-217381732f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "968a1ecb-12ff-4406-a566-4b549346ed08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9d460a-e8b3-4ea0-888f-1dc10446c504",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f789162-64d2-49f3-bf80-b8a8c98adfcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffee6616-ef93-4e5c-85c6-c3c982ee6c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = torch.tensor([[3,6], [10,16], [9,20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52d9d92b-e034-4046-8a73-3b22965cbc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  6],\n",
       "        [10, 16],\n",
       "        [ 9, 20]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59874185-5d33-4874-b8a4-20d3abb593d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the number of rows and columns in metrix 't3'\n",
    "t3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56438b9e-627b-476a-a108-930aaebe5b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking the shape for a three dimensional tenor \n",
    "t4 = torch.tensor([[[3,6], [10,16], [23,34]], [[34,67], [9,20], [9,13]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0369823d-66e1-4018-82fc-c99cf9067976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3,  6],\n",
       "         [10, 16],\n",
       "         [23, 34]],\n",
       "\n",
       "        [[34, 67],\n",
       "         [ 9, 20],\n",
       "         [ 9, 13]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1e0469e-98bd-4724-af92-ba3719069927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e03f9f92-4341-4c0e-bc1d-d585177f2d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape ## For a scaler tensor there will be no shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cba8063-7d5f-41b9-82e1-7ffbc98edc68",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "969cf119-6171-4b0a-8c48-f1c558adf320",
   "metadata": {},
   "source": [
    "#### Tensor Operatrions and Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c170011-5541-4b6f-a466-0a6b3bfeb496",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(8)\n",
    "w = torch.tensor(5.0, requires_grad=True) ## later we would be differentiating a function with respect to this variable\n",
    "b = torch.tensor(4.0, requires_grad=True) ## later we would be differentiating a function with respect to this variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac646cc-c636-4636-bae6-f9b6faa50992",
   "metadata": {},
   "source": [
    "Our parametric function is : y = w*x + b ; where w and b are the parameters. Now we can use the '.backward' method in order to calculate the partial derivatives dy/dw and dy/db. We can calculate the derivative of y with respect to the tensors w and b because those tensors have 'requires_grad' set to true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cee8928c-007c-4c29-bcff-17e9b1c7a2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = w*x + b ## function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51dd614a-b6eb-4537-87d8-0bab5cb91635",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing derivatives\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f2a764b-2c16-43be-9506-63937441b0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx = None\n",
      "dy/dw = tensor(8.)\n",
      "dy/db = tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print('dy/dx =', x.grad)\n",
    "print('dy/dw =', w.grad)\n",
    "print('dy/db =', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184282e1-d258-4fc1-ba68-4ffbc5f78459",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d04c26d-59f4-4fd2-b98f-0b8afe26bc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating metrix with same elements\n",
    "t5 = torch.full((3,2), 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae562714-7319-46eb-9d1b-9aa29c43f8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[28, 28],\n",
       "        [28, 28],\n",
       "        [28, 28]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f35af284-b958-4097-ad2b-945ac3f25b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  6],\n",
       "        [10, 16],\n",
       "        [ 9, 20]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51f1e1b8-a344-448c-8813-9674a8a0d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatinating metrices\n",
    "t6 = torch.cat((t3,t5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3b3a01c-5a01-4c82-966c-5c318bd1bac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  6],\n",
       "        [10, 16],\n",
       "        [ 9, 20],\n",
       "        [28, 28],\n",
       "        [28, 28],\n",
       "        [28, 28]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd5b9b21-8923-4852-8888-010532f24cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing sin and cos of all the elemnts of t3\n",
    "t7 = torch.sin(t3)\n",
    "t8 = torch.cos(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7b517b7-fb29-4dc7-8413-50075277980f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1411, -0.2794],\n",
       "        [-0.5440, -0.2879],\n",
       "        [ 0.4121,  0.9129]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6212760-3429-480a-a9de-3d6d3ace684e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9900,  0.9602],\n",
       "        [-0.8391, -0.9577],\n",
       "        [-0.9111,  0.4081]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc9ad3a6-be68-4838-81b7-deff4809748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshaping a metrix\n",
    "t9 = t6.reshape(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9eebffcf-398d-437b-b39f-8032756d029d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  6, 10],\n",
       "        [16,  9, 20],\n",
       "        [28, 28, 28],\n",
       "        [28, 28, 28]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "030814fc-6699-4acd-bacc-f9cf32c906bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t10 = t4.reshape(3,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b5dfce2-e1c0-4027-87e7-18bb869d4534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3,  6],\n",
       "         [10, 16]],\n",
       "\n",
       "        [[23, 34],\n",
       "         [34, 67]],\n",
       "\n",
       "        [[ 9, 20],\n",
       "         [ 9, 13]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7566eb73-41ef-41bb-b111-ee352348f73b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae0a6be8-97ef-4d70-a172-0ea9d8a8f368",
   "metadata": {},
   "source": [
    "#### Interoperability of pytorch with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c8f361f-bf65-437b-bc33-03718bffaecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "t11 = np.array([[34,56,11], [90,56,72], [21,41,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a8abe75-6e8f-42e4-9c5c-48bf1e17d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t12 = torch.from_numpy(t11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "095f8f38-63d2-4667-810b-b072640ccb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[34, 56, 11],\n",
       "        [90, 56, 72],\n",
       "        [21, 41, 12]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7b7b97a-3f05-47a3-a941-1e5505dad7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "## Checking the datatype both numpy array and torch tensor \n",
    "print(t11.dtype)\n",
    "print(t12.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d4deb-7d06-4825-8bb6-aeccc6bd59e0",
   "metadata": {},
   "source": [
    "Hence both are having the same datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b1a684a-51ee-486a-ab7e-d79300e633f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t13 = t12.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "360a5f97-f9df-439f-b519-43da8a7c7228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34, 56, 11],\n",
       "       [90, 56, 72],\n",
       "       [21, 41, 12]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1ae196-25ff-4d73-8b73-22a9e6415071",
   "metadata": {},
   "source": [
    "So we can convert a numpy variable to a torch tensor and we can convert a torch tensor back to numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d1cea4-6513-4544-9e01-dc719dd1e09d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86890b6e-0f79-4349-bb8d-d389b03d779a",
   "metadata": {},
   "source": [
    "#### Linear regression using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ed5f4c58-1aff-40fe-8f82-3a161632a2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making the training data\n",
    "## The input features are : (temperature, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fb050a86-f186-48e3-9b17-a7ef84af3c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 73.,  67.,  43.],\n",
       "       [ 91.,  88.,  64.],\n",
       "       [ 87., 134.,  58.],\n",
       "       [102.,  43.,  37.],\n",
       "       [ 69.,  96.,  70.]], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs ## The row are the observations and the columns are the features mentioned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "840442b1-ee6d-4b59-be43-6c0f68d2b70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### The target is the number of (apples and oranges) the are sold \n",
    "target = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4e07f779-8e73-4d78-94f8-26aaefef347c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 56.,  70.],\n",
       "       [ 81., 101.],\n",
       "       [119., 133.],\n",
       "       [ 22.,  37.],\n",
       "       [103., 119.]], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d335fd7c-c293-46d8-8cd9-c84c4bd35916",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(inputs)\n",
    "target = torch.from_numpy(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "43bac61d-0039-4595-9a14-f1b5f78027ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: \n",
      " tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]]) \n",
      "\n",
      "target: \n",
      " tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "print('inputs:', '\\n', inputs, '\\n')\n",
    "print('target:', '\\n', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "af8e0331-8930-46fc-8189-dacbcbe58d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weights and biases\n",
    "w = torch.randn(2,3, requires_grad = True) ## one set of three weights are for apples and one set of three weights are for oranges\n",
    "b = torch.randn(2, requires_grad = True) ## one bias is for apples and one bias is for oranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7f20b278-1f2a-4a0b-b88b-937226355ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: \n",
      " tensor([[-1.2105,  1.5428, -0.2436],\n",
      "        [-0.6959,  1.2338, -0.0758]], requires_grad=True) \n",
      "\n",
      "biases: \n",
      " tensor([-0.1869, -0.7026], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('weights:', '\\n', w, '\\n')\n",
    "print('biases:', '\\n', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "514c24ba-ceba-4dab-8ddd-5f74d6d82b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "def model(x):  \n",
    "    return x @ w.t() + b ## Taking the transpose of 'w' before calculating the dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "334ac4c7-81b1-4a5d-8fc7-9c686862dab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: \n",
      " tensor([[  4.3382,  27.9001],\n",
      "        [  9.8319,  39.6911],\n",
      "        [ 87.1021,  99.6830],\n",
      "        [-66.3303, -21.4362],\n",
      "        [ 47.3430,  64.4158]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Prediction \n",
    "pred = model(inputs)\n",
    "print('prediction:', '\\n', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d8d04963-7bb7-459b-b19c-35b6db89951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss function: MSE\n",
    "def MSE(actual, predicted):\n",
    "    diff = actual-predicted\n",
    "    return torch.sum(diff**2)/diff.numel() ## numel stands for number of elements in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4806107d-6a33-4983-83c0-476cb88bd7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3268.6699, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = MSE(target, pred)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b232e2e7-a72d-4603-9333-70f31c57ef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Loss = tensor(3268.6699, grad_fn=<DivBackward0>)\n",
      "Epoch  1 : Loss = tensor(2353.7983, grad_fn=<DivBackward0>)\n",
      "Epoch  2 : Loss = tensor(1735.6650, grad_fn=<DivBackward0>)\n",
      "Epoch  3 : Loss = tensor(1317.5183, grad_fn=<DivBackward0>)\n",
      "Epoch  4 : Loss = tensor(1034.1597, grad_fn=<DivBackward0>)\n",
      "Epoch  5 : Loss = tensor(841.6522, grad_fn=<DivBackward0>)\n",
      "Epoch  6 : Loss = tensor(710.3871, grad_fn=<DivBackward0>)\n",
      "Epoch  7 : Loss = tensor(620.4112, grad_fn=<DivBackward0>)\n",
      "Epoch  8 : Loss = tensor(558.2781, grad_fn=<DivBackward0>)\n",
      "Epoch  9 : Loss = tensor(514.9259, grad_fn=<DivBackward0>)\n",
      "Epoch  10 : Loss = tensor(484.2484, grad_fn=<DivBackward0>)\n",
      "Epoch  11 : Loss = tensor(462.1304, grad_fn=<DivBackward0>)\n",
      "Epoch  12 : Loss = tensor(445.7978, grad_fn=<DivBackward0>)\n",
      "Epoch  13 : Loss = tensor(433.3817, grad_fn=<DivBackward0>)\n",
      "Epoch  14 : Loss = tensor(423.6218, grad_fn=<DivBackward0>)\n",
      "Epoch  15 : Loss = tensor(415.6693, grad_fn=<DivBackward0>)\n",
      "Epoch  16 : Loss = tensor(408.9515, grad_fn=<DivBackward0>)\n",
      "Epoch  17 : Loss = tensor(403.0820, grad_fn=<DivBackward0>)\n",
      "Epoch  18 : Loss = tensor(397.8011, grad_fn=<DivBackward0>)\n",
      "Epoch  19 : Loss = tensor(392.9330, grad_fn=<DivBackward0>)\n",
      "Epoch  20 : Loss = tensor(388.3589, grad_fn=<DivBackward0>)\n",
      "Epoch  21 : Loss = tensor(383.9987, grad_fn=<DivBackward0>)\n",
      "Epoch  22 : Loss = tensor(379.7984, grad_fn=<DivBackward0>)\n",
      "Epoch  23 : Loss = tensor(375.7211, grad_fn=<DivBackward0>)\n",
      "Epoch  24 : Loss = tensor(371.7422, grad_fn=<DivBackward0>)\n",
      "Epoch  25 : Loss = tensor(367.8445, grad_fn=<DivBackward0>)\n",
      "Epoch  26 : Loss = tensor(364.0163, grad_fn=<DivBackward0>)\n",
      "Epoch  27 : Loss = tensor(360.2495, grad_fn=<DivBackward0>)\n",
      "Epoch  28 : Loss = tensor(356.5387, grad_fn=<DivBackward0>)\n",
      "Epoch  29 : Loss = tensor(352.8799, grad_fn=<DivBackward0>)\n",
      "Epoch  30 : Loss = tensor(349.2702, grad_fn=<DivBackward0>)\n",
      "Epoch  31 : Loss = tensor(345.7076, grad_fn=<DivBackward0>)\n",
      "Epoch  32 : Loss = tensor(342.1905, grad_fn=<DivBackward0>)\n",
      "Epoch  33 : Loss = tensor(338.7174, grad_fn=<DivBackward0>)\n",
      "Epoch  34 : Loss = tensor(335.2879, grad_fn=<DivBackward0>)\n",
      "Epoch  35 : Loss = tensor(331.9006, grad_fn=<DivBackward0>)\n",
      "Epoch  36 : Loss = tensor(328.5546, grad_fn=<DivBackward0>)\n",
      "Epoch  37 : Loss = tensor(325.2501, grad_fn=<DivBackward0>)\n",
      "Epoch  38 : Loss = tensor(321.9856, grad_fn=<DivBackward0>)\n",
      "Epoch  39 : Loss = tensor(318.7608, grad_fn=<DivBackward0>)\n",
      "Epoch  40 : Loss = tensor(315.5755, grad_fn=<DivBackward0>)\n",
      "Epoch  41 : Loss = tensor(312.4288, grad_fn=<DivBackward0>)\n",
      "Epoch  42 : Loss = tensor(309.3204, grad_fn=<DivBackward0>)\n",
      "Epoch  43 : Loss = tensor(306.2498, grad_fn=<DivBackward0>)\n",
      "Epoch  44 : Loss = tensor(303.2163, grad_fn=<DivBackward0>)\n",
      "Epoch  45 : Loss = tensor(300.2195, grad_fn=<DivBackward0>)\n",
      "Epoch  46 : Loss = tensor(297.2592, grad_fn=<DivBackward0>)\n",
      "Epoch  47 : Loss = tensor(294.3345, grad_fn=<DivBackward0>)\n",
      "Epoch  48 : Loss = tensor(291.4456, grad_fn=<DivBackward0>)\n",
      "Epoch  49 : Loss = tensor(288.5915, grad_fn=<DivBackward0>)\n",
      "Epoch  50 : Loss = tensor(285.7717, grad_fn=<DivBackward0>)\n",
      "Epoch  51 : Loss = tensor(282.9863, grad_fn=<DivBackward0>)\n",
      "Epoch  52 : Loss = tensor(280.2342, grad_fn=<DivBackward0>)\n",
      "Epoch  53 : Loss = tensor(277.5156, grad_fn=<DivBackward0>)\n",
      "Epoch  54 : Loss = tensor(274.8298, grad_fn=<DivBackward0>)\n",
      "Epoch  55 : Loss = tensor(272.1761, grad_fn=<DivBackward0>)\n",
      "Epoch  56 : Loss = tensor(269.5549, grad_fn=<DivBackward0>)\n",
      "Epoch  57 : Loss = tensor(266.9649, grad_fn=<DivBackward0>)\n",
      "Epoch  58 : Loss = tensor(264.4062, grad_fn=<DivBackward0>)\n",
      "Epoch  59 : Loss = tensor(261.8784, grad_fn=<DivBackward0>)\n",
      "Epoch  60 : Loss = tensor(259.3809, grad_fn=<DivBackward0>)\n",
      "Epoch  61 : Loss = tensor(256.9134, grad_fn=<DivBackward0>)\n",
      "Epoch  62 : Loss = tensor(254.4756, grad_fn=<DivBackward0>)\n",
      "Epoch  63 : Loss = tensor(252.0672, grad_fn=<DivBackward0>)\n",
      "Epoch  64 : Loss = tensor(249.6876, grad_fn=<DivBackward0>)\n",
      "Epoch  65 : Loss = tensor(247.3366, grad_fn=<DivBackward0>)\n",
      "Epoch  66 : Loss = tensor(245.0140, grad_fn=<DivBackward0>)\n",
      "Epoch  67 : Loss = tensor(242.7190, grad_fn=<DivBackward0>)\n",
      "Epoch  68 : Loss = tensor(240.4516, grad_fn=<DivBackward0>)\n",
      "Epoch  69 : Loss = tensor(238.2113, grad_fn=<DivBackward0>)\n",
      "Epoch  70 : Loss = tensor(235.9977, grad_fn=<DivBackward0>)\n",
      "Epoch  71 : Loss = tensor(233.8107, grad_fn=<DivBackward0>)\n",
      "Epoch  72 : Loss = tensor(231.6499, grad_fn=<DivBackward0>)\n",
      "Epoch  73 : Loss = tensor(229.5149, grad_fn=<DivBackward0>)\n",
      "Epoch  74 : Loss = tensor(227.4054, grad_fn=<DivBackward0>)\n",
      "Epoch  75 : Loss = tensor(225.3211, grad_fn=<DivBackward0>)\n",
      "Epoch  76 : Loss = tensor(223.2616, grad_fn=<DivBackward0>)\n",
      "Epoch  77 : Loss = tensor(221.2265, grad_fn=<DivBackward0>)\n",
      "Epoch  78 : Loss = tensor(219.2160, grad_fn=<DivBackward0>)\n",
      "Epoch  79 : Loss = tensor(217.2291, grad_fn=<DivBackward0>)\n",
      "Epoch  80 : Loss = tensor(215.2662, grad_fn=<DivBackward0>)\n",
      "Epoch  81 : Loss = tensor(213.3263, grad_fn=<DivBackward0>)\n",
      "Epoch  82 : Loss = tensor(211.4096, grad_fn=<DivBackward0>)\n",
      "Epoch  83 : Loss = tensor(209.5158, grad_fn=<DivBackward0>)\n",
      "Epoch  84 : Loss = tensor(207.6442, grad_fn=<DivBackward0>)\n",
      "Epoch  85 : Loss = tensor(205.7950, grad_fn=<DivBackward0>)\n",
      "Epoch  86 : Loss = tensor(203.9675, grad_fn=<DivBackward0>)\n",
      "Epoch  87 : Loss = tensor(202.1619, grad_fn=<DivBackward0>)\n",
      "Epoch  88 : Loss = tensor(200.3776, grad_fn=<DivBackward0>)\n",
      "Epoch  89 : Loss = tensor(198.6145, grad_fn=<DivBackward0>)\n",
      "Epoch  90 : Loss = tensor(196.8721, grad_fn=<DivBackward0>)\n",
      "Epoch  91 : Loss = tensor(195.1503, grad_fn=<DivBackward0>)\n",
      "Epoch  92 : Loss = tensor(193.4489, grad_fn=<DivBackward0>)\n",
      "Epoch  93 : Loss = tensor(191.7674, grad_fn=<DivBackward0>)\n",
      "Epoch  94 : Loss = tensor(190.1059, grad_fn=<DivBackward0>)\n",
      "Epoch  95 : Loss = tensor(188.4639, grad_fn=<DivBackward0>)\n",
      "Epoch  96 : Loss = tensor(186.8412, grad_fn=<DivBackward0>)\n",
      "Epoch  97 : Loss = tensor(185.2376, grad_fn=<DivBackward0>)\n",
      "Epoch  98 : Loss = tensor(183.6530, grad_fn=<DivBackward0>)\n",
      "Epoch  99 : Loss = tensor(182.0868, grad_fn=<DivBackward0>)\n",
      "Epoch  100 : Loss = tensor(180.5392, grad_fn=<DivBackward0>)\n",
      "Epoch  101 : Loss = tensor(179.0094, grad_fn=<DivBackward0>)\n",
      "Epoch  102 : Loss = tensor(177.4979, grad_fn=<DivBackward0>)\n",
      "Epoch  103 : Loss = tensor(176.0039, grad_fn=<DivBackward0>)\n",
      "Epoch  104 : Loss = tensor(174.5275, grad_fn=<DivBackward0>)\n",
      "Epoch  105 : Loss = tensor(173.0683, grad_fn=<DivBackward0>)\n",
      "Epoch  106 : Loss = tensor(171.6263, grad_fn=<DivBackward0>)\n",
      "Epoch  107 : Loss = tensor(170.2009, grad_fn=<DivBackward0>)\n",
      "Epoch  108 : Loss = tensor(168.7922, grad_fn=<DivBackward0>)\n",
      "Epoch  109 : Loss = tensor(167.3999, grad_fn=<DivBackward0>)\n",
      "Epoch  110 : Loss = tensor(166.0240, grad_fn=<DivBackward0>)\n",
      "Epoch  111 : Loss = tensor(164.6639, grad_fn=<DivBackward0>)\n",
      "Epoch  112 : Loss = tensor(163.3197, grad_fn=<DivBackward0>)\n",
      "Epoch  113 : Loss = tensor(161.9911, grad_fn=<DivBackward0>)\n",
      "Epoch  114 : Loss = tensor(160.6779, grad_fn=<DivBackward0>)\n",
      "Epoch  115 : Loss = tensor(159.3800, grad_fn=<DivBackward0>)\n",
      "Epoch  116 : Loss = tensor(158.0970, grad_fn=<DivBackward0>)\n",
      "Epoch  117 : Loss = tensor(156.8289, grad_fn=<DivBackward0>)\n",
      "Epoch  118 : Loss = tensor(155.5755, grad_fn=<DivBackward0>)\n",
      "Epoch  119 : Loss = tensor(154.3366, grad_fn=<DivBackward0>)\n",
      "Epoch  120 : Loss = tensor(153.1120, grad_fn=<DivBackward0>)\n",
      "Epoch  121 : Loss = tensor(151.9014, grad_fn=<DivBackward0>)\n",
      "Epoch  122 : Loss = tensor(150.7049, grad_fn=<DivBackward0>)\n",
      "Epoch  123 : Loss = tensor(149.5222, grad_fn=<DivBackward0>)\n",
      "Epoch  124 : Loss = tensor(148.3530, grad_fn=<DivBackward0>)\n",
      "Epoch  125 : Loss = tensor(147.1971, grad_fn=<DivBackward0>)\n",
      "Epoch  126 : Loss = tensor(146.0547, grad_fn=<DivBackward0>)\n",
      "Epoch  127 : Loss = tensor(144.9254, grad_fn=<DivBackward0>)\n",
      "Epoch  128 : Loss = tensor(143.8090, grad_fn=<DivBackward0>)\n",
      "Epoch  129 : Loss = tensor(142.7053, grad_fn=<DivBackward0>)\n",
      "Epoch  130 : Loss = tensor(141.6142, grad_fn=<DivBackward0>)\n",
      "Epoch  131 : Loss = tensor(140.5358, grad_fn=<DivBackward0>)\n",
      "Epoch  132 : Loss = tensor(139.4694, grad_fn=<DivBackward0>)\n",
      "Epoch  133 : Loss = tensor(138.4153, grad_fn=<DivBackward0>)\n",
      "Epoch  134 : Loss = tensor(137.3732, grad_fn=<DivBackward0>)\n",
      "Epoch  135 : Loss = tensor(136.3429, grad_fn=<DivBackward0>)\n",
      "Epoch  136 : Loss = tensor(135.3244, grad_fn=<DivBackward0>)\n",
      "Epoch  137 : Loss = tensor(134.3173, grad_fn=<DivBackward0>)\n",
      "Epoch  138 : Loss = tensor(133.3219, grad_fn=<DivBackward0>)\n",
      "Epoch  139 : Loss = tensor(132.3376, grad_fn=<DivBackward0>)\n",
      "Epoch  140 : Loss = tensor(131.3643, grad_fn=<DivBackward0>)\n",
      "Epoch  141 : Loss = tensor(130.4023, grad_fn=<DivBackward0>)\n",
      "Epoch  142 : Loss = tensor(129.4509, grad_fn=<DivBackward0>)\n",
      "Epoch  143 : Loss = tensor(128.5104, grad_fn=<DivBackward0>)\n",
      "Epoch  144 : Loss = tensor(127.5804, grad_fn=<DivBackward0>)\n",
      "Epoch  145 : Loss = tensor(126.6608, grad_fn=<DivBackward0>)\n",
      "Epoch  146 : Loss = tensor(125.7517, grad_fn=<DivBackward0>)\n",
      "Epoch  147 : Loss = tensor(124.8529, grad_fn=<DivBackward0>)\n",
      "Epoch  148 : Loss = tensor(123.9638, grad_fn=<DivBackward0>)\n",
      "Epoch  149 : Loss = tensor(123.0850, grad_fn=<DivBackward0>)\n",
      "Epoch  150 : Loss = tensor(122.2160, grad_fn=<DivBackward0>)\n",
      "Epoch  151 : Loss = tensor(121.3564, grad_fn=<DivBackward0>)\n",
      "Epoch  152 : Loss = tensor(120.5066, grad_fn=<DivBackward0>)\n",
      "Epoch  153 : Loss = tensor(119.6662, grad_fn=<DivBackward0>)\n",
      "Epoch  154 : Loss = tensor(118.8352, grad_fn=<DivBackward0>)\n",
      "Epoch  155 : Loss = tensor(118.0134, grad_fn=<DivBackward0>)\n",
      "Epoch  156 : Loss = tensor(117.2009, grad_fn=<DivBackward0>)\n",
      "Epoch  157 : Loss = tensor(116.3972, grad_fn=<DivBackward0>)\n",
      "Epoch  158 : Loss = tensor(115.6026, grad_fn=<DivBackward0>)\n",
      "Epoch  159 : Loss = tensor(114.8167, grad_fn=<DivBackward0>)\n",
      "Epoch  160 : Loss = tensor(114.0393, grad_fn=<DivBackward0>)\n",
      "Epoch  161 : Loss = tensor(113.2706, grad_fn=<DivBackward0>)\n",
      "Epoch  162 : Loss = tensor(112.5102, grad_fn=<DivBackward0>)\n",
      "Epoch  163 : Loss = tensor(111.7585, grad_fn=<DivBackward0>)\n",
      "Epoch  164 : Loss = tensor(111.0150, grad_fn=<DivBackward0>)\n",
      "Epoch  165 : Loss = tensor(110.2795, grad_fn=<DivBackward0>)\n",
      "Epoch  166 : Loss = tensor(109.5521, grad_fn=<DivBackward0>)\n",
      "Epoch  167 : Loss = tensor(108.8326, grad_fn=<DivBackward0>)\n",
      "Epoch  168 : Loss = tensor(108.1210, grad_fn=<DivBackward0>)\n",
      "Epoch  169 : Loss = tensor(107.4172, grad_fn=<DivBackward0>)\n",
      "Epoch  170 : Loss = tensor(106.7210, grad_fn=<DivBackward0>)\n",
      "Epoch  171 : Loss = tensor(106.0324, grad_fn=<DivBackward0>)\n",
      "Epoch  172 : Loss = tensor(105.3513, grad_fn=<DivBackward0>)\n",
      "Epoch  173 : Loss = tensor(104.6775, grad_fn=<DivBackward0>)\n",
      "Epoch  174 : Loss = tensor(104.0111, grad_fn=<DivBackward0>)\n",
      "Epoch  175 : Loss = tensor(103.3520, grad_fn=<DivBackward0>)\n",
      "Epoch  176 : Loss = tensor(102.6998, grad_fn=<DivBackward0>)\n",
      "Epoch  177 : Loss = tensor(102.0547, grad_fn=<DivBackward0>)\n",
      "Epoch  178 : Loss = tensor(101.4165, grad_fn=<DivBackward0>)\n",
      "Epoch  179 : Loss = tensor(100.7852, grad_fn=<DivBackward0>)\n",
      "Epoch  180 : Loss = tensor(100.1607, grad_fn=<DivBackward0>)\n",
      "Epoch  181 : Loss = tensor(99.5429, grad_fn=<DivBackward0>)\n",
      "Epoch  182 : Loss = tensor(98.9317, grad_fn=<DivBackward0>)\n",
      "Epoch  183 : Loss = tensor(98.3270, grad_fn=<DivBackward0>)\n",
      "Epoch  184 : Loss = tensor(97.7288, grad_fn=<DivBackward0>)\n",
      "Epoch  185 : Loss = tensor(97.1369, grad_fn=<DivBackward0>)\n",
      "Epoch  186 : Loss = tensor(96.5513, grad_fn=<DivBackward0>)\n",
      "Epoch  187 : Loss = tensor(95.9719, grad_fn=<DivBackward0>)\n",
      "Epoch  188 : Loss = tensor(95.3986, grad_fn=<DivBackward0>)\n",
      "Epoch  189 : Loss = tensor(94.8314, grad_fn=<DivBackward0>)\n",
      "Epoch  190 : Loss = tensor(94.2703, grad_fn=<DivBackward0>)\n",
      "Epoch  191 : Loss = tensor(93.7149, grad_fn=<DivBackward0>)\n",
      "Epoch  192 : Loss = tensor(93.1654, grad_fn=<DivBackward0>)\n",
      "Epoch  193 : Loss = tensor(92.6217, grad_fn=<DivBackward0>)\n",
      "Epoch  194 : Loss = tensor(92.0838, grad_fn=<DivBackward0>)\n",
      "Epoch  195 : Loss = tensor(91.5514, grad_fn=<DivBackward0>)\n",
      "Epoch  196 : Loss = tensor(91.0246, grad_fn=<DivBackward0>)\n",
      "Epoch  197 : Loss = tensor(90.5033, grad_fn=<DivBackward0>)\n",
      "Epoch  198 : Loss = tensor(89.9873, grad_fn=<DivBackward0>)\n",
      "Epoch  199 : Loss = tensor(89.4769, grad_fn=<DivBackward0>)\n",
      "Epoch  200 : Loss = tensor(88.9715, grad_fn=<DivBackward0>)\n",
      "Epoch  201 : Loss = tensor(88.4715, grad_fn=<DivBackward0>)\n",
      "Epoch  202 : Loss = tensor(87.9766, grad_fn=<DivBackward0>)\n",
      "Epoch  203 : Loss = tensor(87.4869, grad_fn=<DivBackward0>)\n",
      "Epoch  204 : Loss = tensor(87.0022, grad_fn=<DivBackward0>)\n",
      "Epoch  205 : Loss = tensor(86.5226, grad_fn=<DivBackward0>)\n",
      "Epoch  206 : Loss = tensor(86.0476, grad_fn=<DivBackward0>)\n",
      "Epoch  207 : Loss = tensor(85.5776, grad_fn=<DivBackward0>)\n",
      "Epoch  208 : Loss = tensor(85.1124, grad_fn=<DivBackward0>)\n",
      "Epoch  209 : Loss = tensor(84.6520, grad_fn=<DivBackward0>)\n",
      "Epoch  210 : Loss = tensor(84.1963, grad_fn=<DivBackward0>)\n",
      "Epoch  211 : Loss = tensor(83.7450, grad_fn=<DivBackward0>)\n",
      "Epoch  212 : Loss = tensor(83.2985, grad_fn=<DivBackward0>)\n",
      "Epoch  213 : Loss = tensor(82.8565, grad_fn=<DivBackward0>)\n",
      "Epoch  214 : Loss = tensor(82.4188, grad_fn=<DivBackward0>)\n",
      "Epoch  215 : Loss = tensor(81.9856, grad_fn=<DivBackward0>)\n",
      "Epoch  216 : Loss = tensor(81.5567, grad_fn=<DivBackward0>)\n",
      "Epoch  217 : Loss = tensor(81.1322, grad_fn=<DivBackward0>)\n",
      "Epoch  218 : Loss = tensor(80.7119, grad_fn=<DivBackward0>)\n",
      "Epoch  219 : Loss = tensor(80.2958, grad_fn=<DivBackward0>)\n",
      "Epoch  220 : Loss = tensor(79.8837, grad_fn=<DivBackward0>)\n",
      "Epoch  221 : Loss = tensor(79.4758, grad_fn=<DivBackward0>)\n",
      "Epoch  222 : Loss = tensor(79.0720, grad_fn=<DivBackward0>)\n",
      "Epoch  223 : Loss = tensor(78.6721, grad_fn=<DivBackward0>)\n",
      "Epoch  224 : Loss = tensor(78.2761, grad_fn=<DivBackward0>)\n",
      "Epoch  225 : Loss = tensor(77.8842, grad_fn=<DivBackward0>)\n",
      "Epoch  226 : Loss = tensor(77.4960, grad_fn=<DivBackward0>)\n",
      "Epoch  227 : Loss = tensor(77.1116, grad_fn=<DivBackward0>)\n",
      "Epoch  228 : Loss = tensor(76.7310, grad_fn=<DivBackward0>)\n",
      "Epoch  229 : Loss = tensor(76.3541, grad_fn=<DivBackward0>)\n",
      "Epoch  230 : Loss = tensor(75.9809, grad_fn=<DivBackward0>)\n",
      "Epoch  231 : Loss = tensor(75.6113, grad_fn=<DivBackward0>)\n",
      "Epoch  232 : Loss = tensor(75.2452, grad_fn=<DivBackward0>)\n",
      "Epoch  233 : Loss = tensor(74.8827, grad_fn=<DivBackward0>)\n",
      "Epoch  234 : Loss = tensor(74.5236, grad_fn=<DivBackward0>)\n",
      "Epoch  235 : Loss = tensor(74.1681, grad_fn=<DivBackward0>)\n",
      "Epoch  236 : Loss = tensor(73.8160, grad_fn=<DivBackward0>)\n",
      "Epoch  237 : Loss = tensor(73.4672, grad_fn=<DivBackward0>)\n",
      "Epoch  238 : Loss = tensor(73.1217, grad_fn=<DivBackward0>)\n",
      "Epoch  239 : Loss = tensor(72.7796, grad_fn=<DivBackward0>)\n",
      "Epoch  240 : Loss = tensor(72.4406, grad_fn=<DivBackward0>)\n",
      "Epoch  241 : Loss = tensor(72.1049, grad_fn=<DivBackward0>)\n",
      "Epoch  242 : Loss = tensor(71.7724, grad_fn=<DivBackward0>)\n",
      "Epoch  243 : Loss = tensor(71.4429, grad_fn=<DivBackward0>)\n",
      "Epoch  244 : Loss = tensor(71.1166, grad_fn=<DivBackward0>)\n",
      "Epoch  245 : Loss = tensor(70.7935, grad_fn=<DivBackward0>)\n",
      "Epoch  246 : Loss = tensor(70.4731, grad_fn=<DivBackward0>)\n",
      "Epoch  247 : Loss = tensor(70.1559, grad_fn=<DivBackward0>)\n",
      "Epoch  248 : Loss = tensor(69.8417, grad_fn=<DivBackward0>)\n",
      "Epoch  249 : Loss = tensor(69.5302, grad_fn=<DivBackward0>)\n",
      "Epoch  250 : Loss = tensor(69.2218, grad_fn=<DivBackward0>)\n",
      "Epoch  251 : Loss = tensor(68.9162, grad_fn=<DivBackward0>)\n",
      "Epoch  252 : Loss = tensor(68.6133, grad_fn=<DivBackward0>)\n",
      "Epoch  253 : Loss = tensor(68.3132, grad_fn=<DivBackward0>)\n",
      "Epoch  254 : Loss = tensor(68.0159, grad_fn=<DivBackward0>)\n",
      "Epoch  255 : Loss = tensor(67.7213, grad_fn=<DivBackward0>)\n",
      "Epoch  256 : Loss = tensor(67.4294, grad_fn=<DivBackward0>)\n",
      "Epoch  257 : Loss = tensor(67.1400, grad_fn=<DivBackward0>)\n",
      "Epoch  258 : Loss = tensor(66.8533, grad_fn=<DivBackward0>)\n",
      "Epoch  259 : Loss = tensor(66.5693, grad_fn=<DivBackward0>)\n",
      "Epoch  260 : Loss = tensor(66.2878, grad_fn=<DivBackward0>)\n",
      "Epoch  261 : Loss = tensor(66.0088, grad_fn=<DivBackward0>)\n",
      "Epoch  262 : Loss = tensor(65.7322, grad_fn=<DivBackward0>)\n",
      "Epoch  263 : Loss = tensor(65.4581, grad_fn=<DivBackward0>)\n",
      "Epoch  264 : Loss = tensor(65.1866, grad_fn=<DivBackward0>)\n",
      "Epoch  265 : Loss = tensor(64.9173, grad_fn=<DivBackward0>)\n",
      "Epoch  266 : Loss = tensor(64.6505, grad_fn=<DivBackward0>)\n",
      "Epoch  267 : Loss = tensor(64.3859, grad_fn=<DivBackward0>)\n",
      "Epoch  268 : Loss = tensor(64.1238, grad_fn=<DivBackward0>)\n",
      "Epoch  269 : Loss = tensor(63.8640, grad_fn=<DivBackward0>)\n",
      "Epoch  270 : Loss = tensor(63.6063, grad_fn=<DivBackward0>)\n",
      "Epoch  271 : Loss = tensor(63.3511, grad_fn=<DivBackward0>)\n",
      "Epoch  272 : Loss = tensor(63.0978, grad_fn=<DivBackward0>)\n",
      "Epoch  273 : Loss = tensor(62.8470, grad_fn=<DivBackward0>)\n",
      "Epoch  274 : Loss = tensor(62.5981, grad_fn=<DivBackward0>)\n",
      "Epoch  275 : Loss = tensor(62.3515, grad_fn=<DivBackward0>)\n",
      "Epoch  276 : Loss = tensor(62.1069, grad_fn=<DivBackward0>)\n",
      "Epoch  277 : Loss = tensor(61.8644, grad_fn=<DivBackward0>)\n",
      "Epoch  278 : Loss = tensor(61.6240, grad_fn=<DivBackward0>)\n",
      "Epoch  279 : Loss = tensor(61.3857, grad_fn=<DivBackward0>)\n",
      "Epoch  280 : Loss = tensor(61.1493, grad_fn=<DivBackward0>)\n",
      "Epoch  281 : Loss = tensor(60.9150, grad_fn=<DivBackward0>)\n",
      "Epoch  282 : Loss = tensor(60.6826, grad_fn=<DivBackward0>)\n",
      "Epoch  283 : Loss = tensor(60.4521, grad_fn=<DivBackward0>)\n",
      "Epoch  284 : Loss = tensor(60.2236, grad_fn=<DivBackward0>)\n",
      "Epoch  285 : Loss = tensor(59.9971, grad_fn=<DivBackward0>)\n",
      "Epoch  286 : Loss = tensor(59.7723, grad_fn=<DivBackward0>)\n",
      "Epoch  287 : Loss = tensor(59.5494, grad_fn=<DivBackward0>)\n",
      "Epoch  288 : Loss = tensor(59.3283, grad_fn=<DivBackward0>)\n",
      "Epoch  289 : Loss = tensor(59.1090, grad_fn=<DivBackward0>)\n",
      "Epoch  290 : Loss = tensor(58.8916, grad_fn=<DivBackward0>)\n",
      "Epoch  291 : Loss = tensor(58.6759, grad_fn=<DivBackward0>)\n",
      "Epoch  292 : Loss = tensor(58.4620, grad_fn=<DivBackward0>)\n",
      "Epoch  293 : Loss = tensor(58.2498, grad_fn=<DivBackward0>)\n",
      "Epoch  294 : Loss = tensor(58.0393, grad_fn=<DivBackward0>)\n",
      "Epoch  295 : Loss = tensor(57.8305, grad_fn=<DivBackward0>)\n",
      "Epoch  296 : Loss = tensor(57.6234, grad_fn=<DivBackward0>)\n",
      "Epoch  297 : Loss = tensor(57.4180, grad_fn=<DivBackward0>)\n",
      "Epoch  298 : Loss = tensor(57.2140, grad_fn=<DivBackward0>)\n",
      "Epoch  299 : Loss = tensor(57.0118, grad_fn=<DivBackward0>)\n",
      "Epoch  300 : Loss = tensor(56.8112, grad_fn=<DivBackward0>)\n",
      "Epoch  301 : Loss = tensor(56.6121, grad_fn=<DivBackward0>)\n",
      "Epoch  302 : Loss = tensor(56.4146, grad_fn=<DivBackward0>)\n",
      "Epoch  303 : Loss = tensor(56.2187, grad_fn=<DivBackward0>)\n",
      "Epoch  304 : Loss = tensor(56.0243, grad_fn=<DivBackward0>)\n",
      "Epoch  305 : Loss = tensor(55.8312, grad_fn=<DivBackward0>)\n",
      "Epoch  306 : Loss = tensor(55.6399, grad_fn=<DivBackward0>)\n",
      "Epoch  307 : Loss = tensor(55.4498, grad_fn=<DivBackward0>)\n",
      "Epoch  308 : Loss = tensor(55.2613, grad_fn=<DivBackward0>)\n",
      "Epoch  309 : Loss = tensor(55.0742, grad_fn=<DivBackward0>)\n",
      "Epoch  310 : Loss = tensor(54.8886, grad_fn=<DivBackward0>)\n",
      "Epoch  311 : Loss = tensor(54.7043, grad_fn=<DivBackward0>)\n",
      "Epoch  312 : Loss = tensor(54.5215, grad_fn=<DivBackward0>)\n",
      "Epoch  313 : Loss = tensor(54.3400, grad_fn=<DivBackward0>)\n",
      "Epoch  314 : Loss = tensor(54.1598, grad_fn=<DivBackward0>)\n",
      "Epoch  315 : Loss = tensor(53.9810, grad_fn=<DivBackward0>)\n",
      "Epoch  316 : Loss = tensor(53.8035, grad_fn=<DivBackward0>)\n",
      "Epoch  317 : Loss = tensor(53.6274, grad_fn=<DivBackward0>)\n",
      "Epoch  318 : Loss = tensor(53.4525, grad_fn=<DivBackward0>)\n",
      "Epoch  319 : Loss = tensor(53.2789, grad_fn=<DivBackward0>)\n",
      "Epoch  320 : Loss = tensor(53.1067, grad_fn=<DivBackward0>)\n",
      "Epoch  321 : Loss = tensor(52.9356, grad_fn=<DivBackward0>)\n",
      "Epoch  322 : Loss = tensor(52.7658, grad_fn=<DivBackward0>)\n",
      "Epoch  323 : Loss = tensor(52.5972, grad_fn=<DivBackward0>)\n",
      "Epoch  324 : Loss = tensor(52.4298, grad_fn=<DivBackward0>)\n",
      "Epoch  325 : Loss = tensor(52.2636, grad_fn=<DivBackward0>)\n",
      "Epoch  326 : Loss = tensor(52.0986, grad_fn=<DivBackward0>)\n",
      "Epoch  327 : Loss = tensor(51.9347, grad_fn=<DivBackward0>)\n",
      "Epoch  328 : Loss = tensor(51.7721, grad_fn=<DivBackward0>)\n",
      "Epoch  329 : Loss = tensor(51.6105, grad_fn=<DivBackward0>)\n",
      "Epoch  330 : Loss = tensor(51.4502, grad_fn=<DivBackward0>)\n",
      "Epoch  331 : Loss = tensor(51.2909, grad_fn=<DivBackward0>)\n",
      "Epoch  332 : Loss = tensor(51.1328, grad_fn=<DivBackward0>)\n",
      "Epoch  333 : Loss = tensor(50.9758, grad_fn=<DivBackward0>)\n",
      "Epoch  334 : Loss = tensor(50.8197, grad_fn=<DivBackward0>)\n",
      "Epoch  335 : Loss = tensor(50.6648, grad_fn=<DivBackward0>)\n",
      "Epoch  336 : Loss = tensor(50.5110, grad_fn=<DivBackward0>)\n",
      "Epoch  337 : Loss = tensor(50.3582, grad_fn=<DivBackward0>)\n",
      "Epoch  338 : Loss = tensor(50.2063, grad_fn=<DivBackward0>)\n",
      "Epoch  339 : Loss = tensor(50.0557, grad_fn=<DivBackward0>)\n",
      "Epoch  340 : Loss = tensor(49.9059, grad_fn=<DivBackward0>)\n",
      "Epoch  341 : Loss = tensor(49.7572, grad_fn=<DivBackward0>)\n",
      "Epoch  342 : Loss = tensor(49.6095, grad_fn=<DivBackward0>)\n",
      "Epoch  343 : Loss = tensor(49.4627, grad_fn=<DivBackward0>)\n",
      "Epoch  344 : Loss = tensor(49.3170, grad_fn=<DivBackward0>)\n",
      "Epoch  345 : Loss = tensor(49.1721, grad_fn=<DivBackward0>)\n",
      "Epoch  346 : Loss = tensor(49.0283, grad_fn=<DivBackward0>)\n",
      "Epoch  347 : Loss = tensor(48.8853, grad_fn=<DivBackward0>)\n",
      "Epoch  348 : Loss = tensor(48.7433, grad_fn=<DivBackward0>)\n",
      "Epoch  349 : Loss = tensor(48.6023, grad_fn=<DivBackward0>)\n",
      "Epoch  350 : Loss = tensor(48.4620, grad_fn=<DivBackward0>)\n",
      "Epoch  351 : Loss = tensor(48.3227, grad_fn=<DivBackward0>)\n",
      "Epoch  352 : Loss = tensor(48.1843, grad_fn=<DivBackward0>)\n",
      "Epoch  353 : Loss = tensor(48.0469, grad_fn=<DivBackward0>)\n",
      "Epoch  354 : Loss = tensor(47.9102, grad_fn=<DivBackward0>)\n",
      "Epoch  355 : Loss = tensor(47.7743, grad_fn=<DivBackward0>)\n",
      "Epoch  356 : Loss = tensor(47.6395, grad_fn=<DivBackward0>)\n",
      "Epoch  357 : Loss = tensor(47.5054, grad_fn=<DivBackward0>)\n",
      "Epoch  358 : Loss = tensor(47.3721, grad_fn=<DivBackward0>)\n",
      "Epoch  359 : Loss = tensor(47.2397, grad_fn=<DivBackward0>)\n",
      "Epoch  360 : Loss = tensor(47.1080, grad_fn=<DivBackward0>)\n",
      "Epoch  361 : Loss = tensor(46.9772, grad_fn=<DivBackward0>)\n",
      "Epoch  362 : Loss = tensor(46.8473, grad_fn=<DivBackward0>)\n",
      "Epoch  363 : Loss = tensor(46.7180, grad_fn=<DivBackward0>)\n",
      "Epoch  364 : Loss = tensor(46.5896, grad_fn=<DivBackward0>)\n",
      "Epoch  365 : Loss = tensor(46.4619, grad_fn=<DivBackward0>)\n",
      "Epoch  366 : Loss = tensor(46.3350, grad_fn=<DivBackward0>)\n",
      "Epoch  367 : Loss = tensor(46.2088, grad_fn=<DivBackward0>)\n",
      "Epoch  368 : Loss = tensor(46.0834, grad_fn=<DivBackward0>)\n",
      "Epoch  369 : Loss = tensor(45.9587, grad_fn=<DivBackward0>)\n",
      "Epoch  370 : Loss = tensor(45.8348, grad_fn=<DivBackward0>)\n",
      "Epoch  371 : Loss = tensor(45.7116, grad_fn=<DivBackward0>)\n",
      "Epoch  372 : Loss = tensor(45.5891, grad_fn=<DivBackward0>)\n",
      "Epoch  373 : Loss = tensor(45.4674, grad_fn=<DivBackward0>)\n",
      "Epoch  374 : Loss = tensor(45.3462, grad_fn=<DivBackward0>)\n",
      "Epoch  375 : Loss = tensor(45.2259, grad_fn=<DivBackward0>)\n",
      "Epoch  376 : Loss = tensor(45.1062, grad_fn=<DivBackward0>)\n",
      "Epoch  377 : Loss = tensor(44.9872, grad_fn=<DivBackward0>)\n",
      "Epoch  378 : Loss = tensor(44.8688, grad_fn=<DivBackward0>)\n",
      "Epoch  379 : Loss = tensor(44.7511, grad_fn=<DivBackward0>)\n",
      "Epoch  380 : Loss = tensor(44.6341, grad_fn=<DivBackward0>)\n",
      "Epoch  381 : Loss = tensor(44.5178, grad_fn=<DivBackward0>)\n",
      "Epoch  382 : Loss = tensor(44.4021, grad_fn=<DivBackward0>)\n",
      "Epoch  383 : Loss = tensor(44.2870, grad_fn=<DivBackward0>)\n",
      "Epoch  384 : Loss = tensor(44.1726, grad_fn=<DivBackward0>)\n",
      "Epoch  385 : Loss = tensor(44.0587, grad_fn=<DivBackward0>)\n",
      "Epoch  386 : Loss = tensor(43.9455, grad_fn=<DivBackward0>)\n",
      "Epoch  387 : Loss = tensor(43.8330, grad_fn=<DivBackward0>)\n",
      "Epoch  388 : Loss = tensor(43.7210, grad_fn=<DivBackward0>)\n",
      "Epoch  389 : Loss = tensor(43.6096, grad_fn=<DivBackward0>)\n",
      "Epoch  390 : Loss = tensor(43.4988, grad_fn=<DivBackward0>)\n",
      "Epoch  391 : Loss = tensor(43.3887, grad_fn=<DivBackward0>)\n",
      "Epoch  392 : Loss = tensor(43.2791, grad_fn=<DivBackward0>)\n",
      "Epoch  393 : Loss = tensor(43.1701, grad_fn=<DivBackward0>)\n",
      "Epoch  394 : Loss = tensor(43.0616, grad_fn=<DivBackward0>)\n",
      "Epoch  395 : Loss = tensor(42.9538, grad_fn=<DivBackward0>)\n",
      "Epoch  396 : Loss = tensor(42.8464, grad_fn=<DivBackward0>)\n",
      "Epoch  397 : Loss = tensor(42.7396, grad_fn=<DivBackward0>)\n",
      "Epoch  398 : Loss = tensor(42.6334, grad_fn=<DivBackward0>)\n",
      "Epoch  399 : Loss = tensor(42.5278, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Model Training\n",
    "\n",
    "for i in range(400):     ## we would do 200 iterations\n",
    "    preds = model(inputs)\n",
    "    loss = MSE(target, preds)\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5   ## weight updation rule in gradient discent\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()       ## resetting the weights to zero before recalculating for the next epoch\n",
    "        b.grad.zero_()\n",
    "    \n",
    "    print('Epoch ', i, ':', 'Loss =', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5849ff3a-0396-45fe-8f3a-a0fae1108891",
   "metadata": {},
   "source": [
    "So we can see that the loss has gradually reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "598932e5-b023-4920-bd2b-05408957984c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(42.4226, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "loss = MSE(target, preds)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2bbaddc1-f54a-44a0-b048-3cd5fa3c3c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.0331,  70.4182],\n",
       "        [ 77.4344,  95.9405],\n",
       "        [129.7590, 143.5375],\n",
       "        [ 20.0156,  37.8427],\n",
       "        [ 94.2047, 110.2897]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Final prediction for apples and oranges\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "edcc91fa-c296-4771-a314-e0f62d88fbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab1ac3d-42dc-4ebc-973e-8bdf122aba31",
   "metadata": {},
   "source": [
    "So we can observe that our predictions are quite close to our actual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01494795-9cb1-4193-ab35-cbd63f4281e1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
